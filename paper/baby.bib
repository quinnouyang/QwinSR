@misc{SRCNN,
    title         = {Image Super-Resolution Using Deep Convolutional Networks}, 
    author        = {Chao Dong and Chen Change Loy and Kaiming He and Xiaoou Tang},
    year          = {2015},
    eprint        = {1501.00092},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV}
}

@misc{SRGAN,
    title         = {Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network}, 
    author        = {Christian Ledig and Lucas Theis and Ferenc Huszar and Jose Caballero and Andrew Cunningham and Alejandro Acosta and Andrew Aitken and Alykhan Tejani and Johannes Totz and Zehan Wang and Wenzhe Shi},
    year          = {2017},
    eprint        = {1609.04802},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV}
}

@misc{SwinIR,
    title         = {SwinIR: Image Restoration Using Swin Transformer}, 
    author        = {Jingyun Liang and Jiezhang Cao and Guolei Sun and Kai Zhang and Luc Van Gool and Radu Timofte},
    year          = {2021},
    eprint        = {2108.10257},
    archivePrefix = {arXiv},
    primaryClass  = {eess.IV}
}

@misc{SwinTransformer,
    title         = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows}, 
    author        = {Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
    year          = {2021},
    eprint        = {2103.14030},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV}
}

@article{Overview,
    author  = {Sung Cheol Park and Min Kyu Park and Moon Gi Kang},
    journal = {IEEE Signal Processing Magazine}, 
    title   = {Super-resolution image reconstruction: a technical overview}, 
    year    = {2003},
    volume  = {20},
    number  = {3},
    pages   = {21-36},
    doi     = {10.1109/MSP.2003.1203207}
}

@article{SwinSeg,
    title    = {SwinSeg: Swin transformer and MLP hybrid network for ship segmentation in maritime surveillance system},
    journal  = {Ocean Engineering},
    volume   = {281},
    pages    = {114885},
    year     = {2023},
    issn     = {0029-8018},
    doi      = {https://doi.org/10.1016/j.oceaneng.2023.114885},
    url      = {https://www.sciencedirect.com/science/article/pii/S0029801823012696},
    author   = {Yuqi Zhang and Chaofeng Li and Shaopeng Shang and Xinqiang Chen},
    keywords = {Maritime intelligent transportation system, Maritime surveillance system, Ship segmentation, Swin transformer, Multi-layer perceptron (MLP)},
    abstract = {Accurate identification and segmentation of moving ships to ensure maritime traffic safety has become an important task in maritime intelligent transportation system. With the development of artificial intelligence, maritime surveillance system based on computer vision has been widely studied. However, there are still some problems when applied to the actual maritime scene. For example, the degradation of visible image quality caused by rain, haze, and low illumination leads to a significant reduction in segmentation performance. To improve the performance of ship identification and segmentation under adverse weather conditions, we propose SwinSeg, a hybrid network combining Swin Transformer and lightweight multi-layer perceptron (MLP). To address the lack of suitable open-source datasets in the community, we have collected and labeled a semantic segmentation dataset of marine ships, named SeaShipsSeg. It consists of 1200 visible marine ship images and covers six common ship types (bulk cargo carrier, container ship, fishing boat, general cargo ship, ore carrier, and passenger ship). In addition, synthetic degraded images are added to the dataset to increase its diversity and improve the generalization ability of the network. The experimental results show that the performance of our method is significantly better than the state-of-the-art (SOTA) methods in terms of segmentation accuracy, robustness, and efficiency under different weather conditions. The dataset is available at https://github.com/GrimreaperZ-creator/SeaShipsSeg.}
}

@misc{ESPCN,
    title         = {Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network}, 
    author        = {Wenzhe Shi and Jose Caballero and Ferenc Huszár and Johannes Totz and Andrew P. Aitken and Rob Bishop and Daniel Rueckert and Zehan Wang},
    year          = {2016},
    eprint        = {1609.05158},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV}
}


@article{Set5,
    author = {Bevilacqua, Marco and Roumy, A. and Guillemot, Christine and Alberi-Morel, Marie-Line},
    year = {2012},
    month = {09},
    pages = {},
    title = {Low-Complexity Single Image Super-Resolution Based on Nonnegative Neighbor Embedding},
    doi = {10.5244/C.26.135}
}

@inproceedings{Set14,
    author="Zeyde, Roman
    and Elad, Michael
    and Protter, Matan",
    editor="Boissonnat, Jean-Daniel
    and Chenin, Patrick
    and Cohen, Albert
    and Gout, Christian
    and Lyche, Tom
    and Mazure, Marie-Laurence
    and Schumaker, Larry",
    title="On Single Image Scale-Up Using Sparse-Representations",
    booktitle="Curves and Surfaces",
    year="2012",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="711--730",
    abstract="This paper deals with the single image scale-up problem using sparse-representation modeling. The goal is to recover an original image from its blurred and down-scaled noisy version. Since this problem is highly ill-posed, a prior is needed in order to regularize it. The literature offers various ways to address this problem, ranging from simple linear space-invariant interpolation schemes (e.g., bicubic interpolation), to spatially-adaptive and non-linear filters of various sorts. We embark from a recently-proposed successful algorithm by Yang et. al. [1,2], and similarly assume a local Sparse-Land model on image patches, serving as regularization. Several important modifications to the above-mentioned solution are introduced, and are shown to lead to improved results. These modifications include a major simplification of the overall process both in terms of the computational complexity and the algorithm architecture, using a different training approach for the dictionary-pair, and introducing the ability to operate without a training-set by boot-strapping the scale-up task from the given low-resolution image. We demonstrate the results on true images, showing both visual and PSNR improvements.",
    isbn="978-3-642-27413-8"
}

@inproceedings{BSD100,
    author={Martin, D. and Fowlkes, C. and Tal, D. and Malik, J.},
    booktitle={Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001}, 
    title={A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics}, 
    year={2001},
    volume={2},
    number={},
    pages={416-423 vol.2},
    doi={10.1109/ICCV.2001.937655}
}

@inproceedings{Div2K,
    author={Agustsson, Eirikur and Timofte, Radu},
    booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
    title={NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study}, 
    year={2017},
    volume={},
    number={},
    pages={1122-1131},
    doi={10.1109/CVPRW.2017.150}
}

@article{Manga109,
    title={Sketch-based manga retrieval using manga109 dataset},
    volume={76},
    ISSN={1573-7721},
    url={http://dx.doi.org/10.1007/s11042-016-4020-z},
    DOI={10.1007/s11042-016-4020-z},
    number={20},
    journal={Multimedia Tools and Applications},
    publisher={Springer Science and Business Media LLC},
    author={Matsui, Yusuke and Ito, Kota and Aramaki, Yuji and Fujimoto, Azuma and Ogawa, Toru and Yamasaki, Toshihiko and Aizawa, Kiyoharu},
    year={2016},
    month=nov, pages={21811–21838}
}

@inproceedings{Urban100,
    author={Huang, Jia-Bin and Singh, Abhishek and Ahuja, Narendra},
    booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
    title={Single image super-resolution from transformed self-exemplars}, 
    year={2015},
    volume={},
    number={},
    pages={5197-5206},
    doi={10.1109/CVPR.2015.7299156}
}

@misc{MLPMixer,
    title={MLP-Mixer: An all-MLP Architecture for Vision}, 
    author={Ilya Tolstikhin and Neil Houlsby and Alexander Kolesnikov and Lucas Beyer and Xiaohua Zhai and Thomas Unterthiner and Jessica Yung and Andreas Steiner and Daniel Keysers and Jakob Uszkoreit and Mario Lucic and Alexey Dosovitskiy},
    year={2021},
    eprint={2105.01601},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{PapersWithCode,
    title = "Papers With Code: Computer Vision",
    url   = "https://paperswithcode.com/area/computer-vision"
}

@misc{DLSS,
  author       = {Edward (Shiqiu) Liu, Robert Pottorff, Guilin Liu, Karan Sapra, Jon Barker, David Tarjan, Lei Yang, Kevin Shih, Marco Salvi, Andrew Tao, Bryan Catanzaro},
  howpublished = {Presentation Slides},
  title        = {DLSS 2.0 - Image Reconstruction For Real-time Rendering With Deep Learning},
  year         = {2020}
}

@misc{StableSR,
    title         = {Exploiting Diffusion Prior for Real-World Image Super-Resolution}, 
    author        = {Jianyi Wang and Zongsheng Yue and Shangchen Zhou and Kelvin C. K. Chan and Chen Change Loy},
    year          = {2023},
    eprint        = {2305.07015},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV}
}

@misc{ESRGAN,
    title         = {ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks}, 
    author        = {Xintao Wang and Ke Yu and Shixiang Wu and Jinjin Gu and Yihao Liu and Chao Dong and Chen Change Loy and Yu Qiao and Xiaoou Tang},
    year          = {2018},
    eprint        = {1809.00219},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV}
}
